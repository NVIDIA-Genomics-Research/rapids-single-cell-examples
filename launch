#!/usr/bin/python3

import os
import wget
import sys
import json
import argparse
import subprocess

from distutils.version import StrictVersion
from subprocess import run


DOCKER_IMAGE='claraparabricks/single-cell-examples_rapids_cuda10.2:latest'

DATASETS = {
    'hlca_lung': 'https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/krasnow_hlca_10x.sparse.h5ad',
    'dsci_bmmc_60k': """
            https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/dsci_resting_nonzeropeaks.h5ad,
            https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/dsci_resting_peaknames_nonzero.npy,
            https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/dsci_resting_cell_metadata.csv
            """,
    'dsci_bmmc_60k_viz': """
            https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/dsci_resting_nonzeropeaks.h5ad,
            https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/dsci_resting_peaknames_nonzero.npy,
            https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/dsci_resting_cell_metadata.csv
            """,
    '1M_brain': 'https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad'
}

CONDA_ENV_MAPPING = {
    'hlca_lung': 'conda/rapidgenomics_cuda10.2.yml',
    'dsci_bmmc_60k': 'conda/rapidgenomics_cuda10.2.yml',
    'dsci_bmmc_60k_viz': 'conda/rapidgenomics_cuda10.2.viz.yml',
    '1M_brain': 'conda/rapidgenomics_cuda10.2.yml',
}

NOTEBOOKS = {
    'hlca_lung': './notebooks/hlca_lung_gpu_analysis.ipynb',
    'dsci_bmmc_60k': './notebooks/dsci_bmmc_60k_gpu.ipynb',
    'dsci_bmmc_60k_viz': './notebooks/hlca_lung_gpu_analysis-visualization.ipynb',
    '1M_brain': './notebooks/1M_brain_gpu_analysis_uvm.ipynb',
}


class Launcher(object):

    def __init__(self):
        parser = argparse.ArgumentParser(
            description='Example launcher',
            usage='''launch <command> [<args>]

Following commands are wrapped by this tool:
   dataset    : Download dataset
   container  : Start Jupyter notebook in a container
   host       : Start Jupyter notebook on the host
   execute    : Execute am example
   create_env : Create conda environment
''')
        parser.add_argument('command', help='Subcommand to run')
        args = parser.parse_args(sys.argv[1:2])

        if not hasattr(self, args.command):
            print('Unrecognized command')
            parser.print_help()
            exit(1)

        getattr(self, args.command)()


    def _fetch_docker_version(self):
        try:
            version = subprocess.check_output(
                ["docker", "version", "--format", "'{{.Client.Version}}'"],
                universal_newlines=True)
            return version
        except FileNotFoundError as ex:
            print("Please install docker.")
            sys.exit(1)


    def _conda_envs(self):
        try:
            output = subprocess.check_output(["conda", "info", "--envs", "--json"],
                universal_newlines=True)
            envs =  json.loads(output)
            envs = [envFile.split('/')[-1]  for envFile in envs['envs']]
            return envs
        except FileNotFoundError as ex:
            print("Please install and activate conda.")
            sys.exit(1)


    def _create_conda_env(self, env_name):
        available_envs = self._conda_envs()
        if env_name in available_envs:
            print('Env %s already available.' % env_name)
        else:
            try:
                env_yml = CONDA_ENV_MAPPING[env_name]
            except KeyError as ex:
                env_yml = "conda/%s.yml" % (env_name)
                env_name = env_name.replace(".", "_")

            create_cmd = "conda env create --name " + env_name + \
                ' -f ' + env_yml
            print('Creating conda env %s (%s)...' % (env_name, create_cmd))
            run(create_cmd, shell=True)
        run('python3 -m ipykernel install --user --name=%s' % (env_name),
            shell=True)


    def download_dataset(self, datasets, dest_dir):
        for ds in datasets:
            for url in ds.split(','):
                url = url.strip()
                filename = os.path.basename(url)
                filename = os.path.join(dest_dir, filename)
                if not os.path.exists(filename):
                    print("Dowloading %s to %s..." % (url, filename))
                    wget.download(url, filename)

    def dataset(self):
        """
        Downloads a dataset. Datasets are pre-defined as a dictionary DATASETS.
        Each dataset can be a comma seperated HTTP URL.
        """
        parser = argparse.ArgumentParser(
            description='dataset')
        parser.add_argument('-d', '--dataDir',
                        dest='data_dir',
                        type=str,
                        required=True,
                        help='Directory to download dataset')
        parser.add_argument('-n', '--datasetName',
                        dest='dataset_name',
                        type=str,
                        required=False,
                        help='Name of dataset. Without this parameter all datasets will be downloaded. Available datasets are %s' %
                            ', '.join(list(DATASETS.keys())))
        args = parser.parse_args(sys.argv[2:])

        datasets = []
        if args.dataset_name is not None:
            datasets.append(DATASETS[args.dataset_name])
        else:
            datasets = DATASETS.values()

        self.download_dataset(datasets, args.data_dir)

    def container(self):
        parser = argparse.ArgumentParser(
            description='container')
        parser.add_argument('-d', '--dataDir',
                        dest='data_dir',
                        type=str,
                        required=True,
                        help='Directory with datasets')
        parser.add_argument('-p', '--jupyterPort',
                        dest='jupyter_port',
                        type=int,
                        required=False,
                        default=8888,
                        help='Port for jupyter')
        args = parser.parse_args(sys.argv[2:])

        docker_version = self._fetch_docker_version().strip().strip("'")

        # nvidia docker toolkit command parameter
        runtime_arg = '--gpus all'
        if StrictVersion(docker_version.strip()) < StrictVersion("19.03.0"):
            print('Old docker version %s. Please upgrade docker' % \
                (docker_version))
            runtime_arg = '--runtime=nvidia'

        cmd ="""docker run \
            %s --rm \
            --user $(id -u):$(id -g) \
            -p %d:8888 \
            -v %s:/workspace/rapids-single-cell-examples/data \
            -e HOME=/workspace/rapids-single-cell-examples/data \
            -w /workspace/rapids-single-cell-examples \
            -it %s \
            /opt/conda/envs/rapids/bin/jupyter-lab \
                --no-browser \
                --port=8888 \
                --ip=0.0.0.0 \
                --notebook-dir=/workspace \
                --NotebookApp.password=\"\" \
                --NotebookApp.token=\"\" \
                --NotebookApp.password_required=False
        """ % (runtime_arg, args.jupyter_port, args.data_dir, DOCKER_IMAGE)
        run(cmd, check=True, shell=True)

    def create_env(self):
        parser = argparse.ArgumentParser(
            description='miniasm')
        parser.add_argument('-e', '--env',
                        dest='env',
                        type=str,
                        required=True,
                        help='Example for which to create conda env. ' +
                        ', '.join(list(DATASETS.keys())))

        args = parser.parse_args(sys.argv[2:])
        self._create_conda_env(args.env)

    def host(self):
        parser = argparse.ArgumentParser(
            description='miniasm')
        parser.add_argument('-d', '--dataDir',
                        dest='data_dir',
                        type=str,
                        required=True,
                        help='Directory with datasets')
        parser.add_argument('-e', '--example',
                        dest='example',
                        type=str,
                        required=True,
                        help='Example to execute. ' +
                        ', '.join(list(DATASETS.keys())))
        parser.add_argument('-p', '--jupyterPort',
                        dest='jupyter_port',
                        type=int,
                        required=False,
                        default=8888,
                        help='Port for jupyter')

        args = parser.parse_args(sys.argv[2:])
        self._create_conda_env(args.example)

        # make sure the required files are downloaded
        self.download_dataset([DATASETS[args.example]], args.data_dir)

        print('Activating env %s...' % args.example)
        run(['bash', '-c',
            'source activate %s; jupyter-lab -y --port=%d --ip=0.0.0.0' %
            (args.example, args.jupyter_port)],
            check=True)

    def execute(self):
        parser = argparse.ArgumentParser(
            description='miniasm')
        parser.add_argument('-d', '--dataDir',
                        dest='data_dir',
                        type=str,
                        required=True,
                        help='Directory with datasets')
        parser.add_argument('-e', '--example',
                        dest='example',
                        type=str,
                        required=True,
                        help='Example to execute. ' +
                        ', '.join(list(DATASETS.keys())))

        args = parser.parse_args(sys.argv[2:])

        available_envs = self._conda_envs()
        if args.example in available_envs:
            print('Env %s already available.' % args.example)
        else:
            create_cmd = "conda env create --name " + args.example + \
                ' -f ' + CONDA_ENV_MAPPING[args.example]
            print('Creating conda env %s (%s)...' % (args.example, create_cmd))
            run(create_cmd, shell=True)
        run('python3 -m ipykernel install --user --name=%s' % (args.example),
            shell=True)

        # make sure the required files are downloaded
        datasets = [DATASETS[args.example]]
        self.download_dataset(datasets, args.data_dir)

        print('Activating env %s...' % args.example)
        run(['bash', '-c',
            'source activate %s; jupyter nbconvert --execute --clear-output %s' %
            (args.example, NOTEBOOKS[args.example])],
            check=True)

def main():
    Launcher()


if __name__ == '__main__':
    main()
