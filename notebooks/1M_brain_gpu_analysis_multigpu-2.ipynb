{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAPIDS & Scanpy Single-Cell RNA-seq Multi-GPU Workflow on 1 Million Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2020, NVIDIA CORPORATION.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\") you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0 \n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates a single-cell RNA analysis workflow that begins with preprocessing a count matrix of size `(n_gene, n_cell)` and results in a visualization of the clustered cells for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes, we use a dataset of 1M brain cells with Unified Virtual Memory to oversubscribe GPU memory. We then use dask to scale PCA, K-means clustering, and UMAP across multiple GPUs.\n",
    "\n",
    "See the README for instructions to download this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "\n",
    "import cupy\n",
    "import cudf\n",
    "import math\n",
    "\n",
    "import h5py\n",
    "import scipy\n",
    "\n",
    "import dask\n",
    "import dask_cudf\n",
    "import rmm\n",
    "\n",
    "from numba import cuda\n",
    "\n",
    "from dask_cuda import initialize\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask import delayed, dataframe\n",
    "from dask.dataframe.utils import make_meta\n",
    "from dask.distributed import Client\n",
    "\n",
    "\n",
    "from cuml.manifold import TSNE\n",
    "from cuml.manifold import UMAP\n",
    "\n",
    "from cuml.dask.decomposition import PCA\n",
    "from cuml.dask.cluster import KMeans\n",
    "from cuml.dask.manifold import UMAP as distUMAP\n",
    "\n",
    "import rapids_scanpy_funcs\n",
    "import utils\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', 'Expected ')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the RAPIDS memory manager to enable Unified Virtual Memory management, which allows us to oversubscribe the GPU memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we provide the path to the sparse `.h5ad` file containing the count matrix to analyze. Please see the README for instructions on how to download the dataset we use here.\n",
    "\n",
    "To run this notebook using your own dataset, please see the README for instructions to convert your own count matrix into this format. Then, replace the path in the cell below with the path to your generated `.h5ad` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, wget\n",
    "# input_file = \"../1M_neurons_filtered_gene_bc_matrices_h5.h5\"\n",
    "# input_file = \"../data/1M_neurons_filtered_gene_bc_matrices_h5.h5\"\n",
    "input_file = \"../data/1M_brain_cells_10X.sparse.h5ad\"\n",
    "\n",
    "if not os.path.exists(input_file):\n",
    "    print('Downloading import file...')\n",
    "    os.makedirs('../data', exist_ok=True)\n",
    "    wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',\n",
    "              input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>ucx://127.0.0.1:44627</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>2</li>\n",
       "  <li><b>Cores: </b>2</li>\n",
       "  <li><b>Memory: </b>33.58 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'ucx://127.0.0.1:44627' processes=2 threads=2, memory=33.58 GB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_start = time.time()\n",
    "\n",
    "enable_tcp_over_ucx = True\n",
    "enable_nvlink = False\n",
    "enable_infiniband = False\n",
    "\n",
    "rmm.reinitialize(managed_memory=True)\n",
    "cupy.cuda.set_allocator(rmm.rmm_cupy_allocator)\n",
    "\n",
    "initialize.initialize(create_cuda_context=True,\n",
    "                      enable_tcp_over_ucx=enable_tcp_over_ucx,\n",
    "                      enable_nvlink=enable_nvlink,\n",
    "                      enable_infiniband=enable_infiniband)\n",
    "cluster = LocalCUDACluster(protocol=\"ucx\",\n",
    "                           CUDA_VISIBLE_DEVICES=[0, 1],\n",
    "                           enable_tcp_over_ucx=enable_tcp_over_ucx,\n",
    "                           enable_nvlink=enable_nvlink,\n",
    "                           enable_infiniband=enable_infiniband)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# marker genes\n",
    "MITO_GENE_PREFIX = \"mt-\"              # Prefix for mitochondrial genes to regress out\n",
    "markers = [\"Stmn2\", \"Hes1\", \"Olig1\"]  # Marker genes for visualization\n",
    "# markers = [\"Stmn2\", \"Hes1\"]         # Marker genes for visualization\n",
    "\n",
    "# filtering cells\n",
    "min_genes_per_cell = 200    # Filter out cells with fewer genes than this expressed \n",
    "max_genes_per_cell = 6000   # Filter out cells with more genes than this expressed \n",
    "min_cells=1                 # Genes containing a number of cells below this value will be filtered\n",
    "\n",
    "# filtering genesinitialize\n",
    "n_top_genes = 4000        # Number of highly variable genes to retain\n",
    "\n",
    "# PCA\n",
    "n_components = 50         # Number of principal components to compute\n",
    "pca_train_ratio = 0.35    # percentage of cells to use for PCA training\n",
    "n_pca_batches = 10\n",
    "\n",
    "# t-SNE\n",
    "tsne_n_pcs = 20        # Number of principal components to use for t-SNE\n",
    "\n",
    "# k-means\n",
    "k = 35                 # Number of clusters for k-means\n",
    "\n",
    "# KNN\n",
    "n_neighbors = 15       # Number of nearest neighbors for KNN graph\n",
    "knn_n_pcs = 50         # Number of principal components to use for finding nearest neighbors\n",
    "\n",
    "# UMAP\n",
    "umap_train_ratio = 0.35\n",
    "umap_min_dist = 0.3\n",
    "umap_spread = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating delayed sub-arrays\n",
      "Concate sub-arrays...\n",
      "Compute and persist arrays...\n",
      "CPU times: user 2.33 s, sys: 2.75 s, total: 5.08 s\n",
      "Wall time: 9.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TODO: Compute batches using total Rows and columns\n",
    "BATCHES = 20\n",
    "\n",
    "# Read along with filtering\n",
    "\n",
    "with h5py.File(input_file, 'r') as h5f:\n",
    "    genes = h5f['/var/gene_ids']\n",
    "    indices = h5f['/X/indptr']\n",
    "    data = h5f['/X/data']\n",
    "\n",
    "    total_cols = genes.shape[0] \n",
    "    total_rows = indices.shape[0] - 1\n",
    "    batch_rows = math.ceil(total_rows / BATCHES)\n",
    "\n",
    "\n",
    "@cuda.jit\n",
    "def fill(start_indices, end_indices, data, out):\n",
    "    row = cuda.grid(1)\n",
    "    start = start_indices[row]\n",
    "    end = end_indices[row]\n",
    "    for i in range(start, end):\n",
    "        out[row][i - start] = data[i]\n",
    "\n",
    "\n",
    "@delayed\n",
    "def read_partition(sample_file, \n",
    "                   ds_data, ds_indices, ds_indptr, \n",
    "                   batch, total_rows, rows, total_cols,\n",
    "                   min_genes_per_cell=200, max_genes_per_cell=6000):\n",
    "    \"\"\"\n",
    "    Loads a single partition from HDF5 file.\n",
    "    \"\"\"\n",
    "    batch_start = batch * rows\n",
    "    batch_end = min(total_rows, batch * rows + rows)\n",
    "\n",
    "    with h5py.File(input_file, 'r') as h5f:\n",
    "        # Read all things row pointers for one worker\n",
    "        indptrs = h5f[ds_indptr]\n",
    "        start_ptr = indptrs[batch_start]\n",
    "        end_ptr = indptrs[batch_end]\n",
    "        sub_indptrs = cupy.array(indptrs[batch_start:batch_end])\n",
    "\n",
    "        # Read all things data for one worker\n",
    "        data = h5f[ds_data]\n",
    "        sub_data = cupy.array(data[start_ptr:end_ptr])\n",
    "\n",
    "        # Read all things column pointers for one worker\n",
    "        indices = h5f[ds_indices]\n",
    "        sub_indices = cupy.array(data[start_ptr:end_ptr])\n",
    "\n",
    "        # Apply Filters for min and max genes\n",
    "        # TODO: Add barcode filtering here.\n",
    "        degrees = cupy.diff(sub_indptrs)\n",
    "        degrees = cupy.where((degrees >= min_genes_per_cell) & (degrees <= max_genes_per_cell))\n",
    "        sub_indptrs = cupy.extract(degrees, sub_indptrs)\n",
    "\n",
    "        # recompute the row pointer for the partial dataset\n",
    "        sub_indptrs = sub_indptrs - start_ptr\n",
    "        \n",
    "    ret = cupy.sparse.csr_matrix((sub_data, sub_indices, sub_indptrs),\n",
    "                                 shape=(len(sub_indptrs) - 1, total_cols))\n",
    "    return ret\n",
    "\n",
    "\n",
    "print('Creating delayed sub-arrays')\n",
    "dls = []\n",
    "for batch in range(BATCHES):\n",
    "    #TODO Remove this condition before release. Only for testing\n",
    "    if batch < 3:\n",
    "        rows = min(batch_rows, total_rows - (batch_rows * batch))\n",
    "        dls.append(\n",
    "            dask.array.from_delayed(\n",
    "                read_partition(input_file, \n",
    "                               '/X/data', '/X/indices', '/X/indptr', \n",
    "                               batch, total_rows, rows, total_cols,\n",
    "                               min_genes_per_cell=min_genes_per_cell,\n",
    "                               max_genes_per_cell=max_genes_per_cell),\n",
    "                dtype=cupy.float32,\n",
    "                shape=(rows, total_cols)))\n",
    "\n",
    "\n",
    "print('Concate sub-arrays...')\n",
    "sparse_gpu_array = dask.array.concatenate(dls)\n",
    "\n",
    "print('Compute and persist arrays...')\n",
    "sparse_gpu_array = sparse_gpu_array.persist()\n",
    "sparse_gpu_array = sparse_gpu_array.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_gpu_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the sparse count matrix from an `h5ad` file using Scanpy. The sparse count matrix will then be placed on the GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_load_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 25s, sys: 14.9 s, total: 1min 40s\n",
      "Wall time: 1min 33s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1306127, 27998)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "adata = sc.read(input_file)\n",
    "# adata.var_names_make_unique()\n",
    "adata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we select the first 1 million cells in the dataset. We maintain the index of unique genes in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot create a storer if the object is not existing nor a value are passed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/io/hdf.py\u001b[0m in \u001b[0;36mread_hdf\u001b[0;34m(path_or_buf, *args, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;34m\"be GPU accelerated in the future\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     )\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mpd_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcudf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.8/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mread_hdf\u001b[0;34m(path_or_buf, key, mode, errors, where, start, stop, columns, iterator, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m                     )\n\u001b[1;32m    414\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcandidate_only_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v_pathname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         return store.select(\n\u001b[0m\u001b[1;32m    416\u001b[0m             \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.8/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, key, where, start, stop, columns, iterator, chunksize, auto_close)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;31m# create the storer and axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0mwhere\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_term\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_storer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.8/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36m_create_storer\u001b[0;34m(self, group, format, value, encoding, errors)\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mtt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"generic_table\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1662\u001b[0;31m                     raise TypeError(\n\u001b[0m\u001b[1;32m   1663\u001b[0m                         \u001b[0;34m\"cannot create a storer if the object is not existing \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m                         \u001b[0;34m\"nor a value are passed\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot create a storer if the object is not existing nor a value are passed"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# with h5py.File(input_file, 'r') as h5f:\n",
    "#     genes = h5f['/var/gene_ids']\n",
    "#     genes = cudf.Series(genes)\n",
    "\n",
    "genes = cudf.read_hdf(input_file, key='/var/gene_ids', mode='r')\n",
    "genes\n",
    "# type(adata.var_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the shape of the resulting sparse matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1306107, 27998)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_gpu_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the number of non-zero values in the matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2624825464"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_gpu_array.nnz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data load and format time: 798.5459108352661\n"
     ]
    }
   ],
   "source": [
    "data_load_time = time.time()\n",
    "print(\"Total data load and format time: %s\" % (data_load_time-data_load_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filter the count matrix to remove cells with an extreme number of genes expressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.32 s, sys: 3.94 s, total: 6.26 s\n",
      "Wall time: 6.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# FILTERING IS NOT DONE WHILE READING DATA\n",
    "\n",
    "# sparse_gpu_array = rapids_scanpy_funcs.filter_cells(sparse_gpu_array, \n",
    "#                                                     min_genes=min_genes_per_cell, \n",
    "#                                                     max_genes=max_genes_per_cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some genes will now have zero expression in all cells. We filter out such genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sparse_gpu_array, genes = rapids_scanpy_funcs.filter_genes(sparse_gpu_array, genes, min_cells=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of our count matrix is now reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_gpu_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We normalize the count matrix so that the total counts in each cell sum to 1e4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sparse_gpu_array = rapids_scanpy_funcs.normalize_total(sparse_gpu_array, target_sum=1e4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we log transform the count matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sparse_gpu_array = sparse_gpu_array.log1p()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Most Variable Genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the count matrix to an annData object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "adata = anndata.AnnData(sparse_gpu_array.get())\n",
    "adata.var_names = genes.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using scanpy, we filter the count matrix to retain only the most variable genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor=\"cell_ranger\")\n",
    "adata = adata[:, adata.var.highly_variable]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regress out confounding factors (number of counts, mitochondrial gene expression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now perform regression on the count matrix to correct for confounding factors -  for example purposes, we use the number of counts and the expression of mitochondrial genes (named starting with `mt-`).\n",
    "\n",
    "Before regression, we save the 'raw' expression values of the marker genes to use for labeling cells afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = adata.var_names\n",
    "mito_genes = genes.str.startswith(MITO_GENE_PREFIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now calculate the total counts and the percentage of mitochondrial counts for each cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "filtered = adata.X\n",
    "n_counts = filtered.sum(axis=1)\n",
    "percent_mito = (filtered[:,mito_genes].sum(axis=1) / n_counts).ravel()\n",
    "\n",
    "n_counts = cp.array(n_counts).ravel()\n",
    "percent_mito = cp.array(percent_mito).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And perform regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sparse_gpu_array = cp.sparse.csc_matrix(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sparse_gpu_array = rapids_scanpy_funcs.regress_out(sparse_gpu_array, n_counts, percent_mito)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we scale the count matrix to obtain a z-score and apply a cutoff value of 10 standard deviations, obtaining the preprocessed count matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sparse_gpu_array = rapids_scanpy_funcs.scale(sparse_gpu_array, max_value=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_time = time.time()\n",
    "print(\"Total Preprocessing time: %s\" % (preprocess_time-preprocess_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster & Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the preprocessed count matrix as an AnnData object, which is currently in host memory. We also add the expression levels of the marker genes as observations to the annData object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "adata = anndata.AnnData(sparse_gpu_array.get())\n",
    "adata.var_names = genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "genes = cudf.Series(adata.var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "marker_genes_raw = {\n",
    "    (\"%s_raw\" % marker): sparse_gpu_array[:, genes[genes == marker].index[0]].ravel()\n",
    "    for marker in markers\n",
    "}\n",
    "for name, data in marker_genes_raw.items():\n",
    "    adata.obs[name] = data.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use PCA to reduce the dimensionality of the matrix to its top 50 principal components. Here, we use Dask to parallelize across multiple GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_workers = len(client.scheduler_info()['workers'].keys())\n",
    "print(n_workers)\n",
    "\n",
    "chunk_size = int(sparse_gpu_array.shape[0] / (n_workers*10))\n",
    "\n",
    "dask_array = dask.array.from_array(\n",
    "    sparse_gpu_array, \n",
    "    chunks=(chunk_size, -1),\n",
    "    asarray=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PCA multi-GPU time includes initial data transfer, which is about 20gb. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50)\n",
    "dask_array = pca.fit_transform(dask_array)\n",
    "adata.obsm[\"X_pca\"] = dask_array.compute().get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE + k-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "adata.obsm['X_tsne'] = TSNE().fit_transform(adata.obsm[\"X_pca\"][:,:tsne_n_pcs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cluster the cells using k-means on the principal components. For example purposes, we set k=35."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# K-means\n",
    "dask_kmeans_output = KMeans(n_clusters=k).fit_predict(dask_array)\n",
    "adata.obs['kmeans'] = dask_kmeans_output.compute().get().astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the cells using t-SNE and label cells by color according to the k-means clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.tsne(adata, color=[\"kmeans\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We label the cells using the `Stmn2` and `Hes1` marker genes, for neuronal and glial cells respectively. These visualizations show us the separation of neuronal and glial cells on the t-SNE plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sc.pl.tsne(adata, color=[\"Stmn2_raw\"], color_map=\"Blues\", vmax=1, vmin=-0.05)\n",
    "sc.pl.tsne(adata, color=[\"Hes1_raw\"], color_map=\"Blues\", vmax=1, vmin=-0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP + Louvain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the cells using the UMAP algorithm in Rapids. Before UMAP, we need to construct a k-nearest neighbors graph in which each cell is connected to its nearest neighbors. This can be done conveniently using rapids functionality already integrated into Scanpy.\n",
    "\n",
    "Note that Scanpy uses an approximation to the nearest neighbors on the CPU while the GPU version performs an exact search. While both methods are known to yield useful results, some differences in the resulting visualization and clusters can be observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=knn_n_pcs, method='rapids')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UMAP function from Rapids is also integrated into Scanpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "local_model = UMAP(n_epochs=1000, min_dist=umap_min_dist, spread=umap_spread)\n",
    "local_model.fit(adata.obsm[\"X_pca\"][:350000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dist_embeddings = distUMAP(local_model).transform(dask_array)\n",
    "adata.obsm[\"X_umap\"] = dist_embeddings.compute().get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use the Louvain algorithm for graph-based clustering, once again using the `rapids` option in Scanpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sc.tl.louvain(adata, flavor='rapids')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the cells using the UMAP visualization, and using the Louvain clusters as labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sc.pl.umap(adata, color=[\"louvain\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also visualize the cells labeled by expression of the `Stmn2` and `Hes1` marker genes, for neuronal and glial cells respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sc.pl.umap(adata, color=[\"Stmn2_raw\"], color_map=\"Blues\", vmax=1, vmin=-0.05)\n",
    "sc.pl.umap(adata, color=[\"Hes1_raw\"], color_map=\"Blues\", vmax=1, vmin=-0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_time = time.time()\n",
    "print(\"Total cluster time : %s\" % (cluster_time-cluster_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Zoomed View"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The speedup offered by Rapids makes it easy to interactively re-analyze subsets of cells. To illustrate this, we select glial cells (Hes1+) from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reanalysis_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hes1_cells = marker_genes_raw[\"Hes1_raw\"] > 0.0\n",
    "adata = adata[hes1_cells.get(),:]\n",
    "adata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can repeat the dimension reduction, clustering and visualization using this subset of cells in seconds. \n",
    "\n",
    "Finally, we visualize the selected neuronal cells labeled by their new clusters, and by the expression of `Olig1`, a marker gene for oligodendrocytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dask_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "chunk_size = int(sparse_gpu_array.shape[0] / (n_workers*10))\n",
    "dask_array = dask.array.from_array(cp.asarray(adata.X), \n",
    "                                   chunks=(chunk_size, -1))\n",
    "dask_array = dask_array.persist()\n",
    "\n",
    "client.rebalance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dask_array = pca.fit_transform(dask_array)\n",
    "adata.obsm['X_pca'] = dask_array.compute().get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=knn_n_pcs, method='rapids')\n",
    "sc.tl.umap(adata, min_dist=umap_min_dist, spread=umap_spread, method='rapids')\n",
    "sc.tl.louvain(adata, flavor='rapids')\n",
    "\n",
    "sc.pl.umap(adata, color=[\"louvain\"])\n",
    "sc.pl.umap(adata, color=[\"Olig1_raw\"], color_map=\"Blues\", vmax=1, vmin=-0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reanalysis_time = time.time()\n",
    "print(\"Total reanalysis time : %s\" % (reanalysis_time-reanalysis_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Full time: %s\" % (time.time() - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
